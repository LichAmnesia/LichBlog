---
title: 信息论基础 - 熵相关介绍
date: 2016-05-11 01:45:04
tags:
    - mathematic
---

　　本文介绍熵有关最基本公式和定理。

<!-- more -->
# 1. 熵定义

　　香农把随机变量X的熵值 $Η$（希腊字母$H$）定义如下，其值域为${x1, ..., xn}$

$$
\begin{align}
H(X) &= - \sum\_{x \in X} p(x) \log\_{2} p(x) \\\\
&= \sum\_{x \in X} p(x) \frac{1}{\log\_{2} p(x)} \\\\
&= E(\log\frac{1}{p(x)})
\end{align}
$$

# 2. 联合熵
$$
\begin{align}
H(X,Y) &= -\sum\_{x \in X} \sum\_{y \in Y} p(x,y) \log\_{2}p(x,y) \\\\
H(Y | X) &= \sum\_{x \in X} p(x) H(Y | X = x) \\\\
&= \sum\_{x \in X} p(x)[- \sum\_{y \in Y} p(y|x) \log\_{2}p(y|x) ] \\\\
&= - \sum\_{x \in X} \sum\_{y \in Y} p(x,y) \log\_{2}p(y|x) 
\end{align}
$$

　　互信息也用到了联合熵：
$$
\begin{align}
I(X;Y) &= H(X) - H(X|Y) \\\\
I(X;Y) &= H(X) + H(Y) - H(X,Y) \\\\
I(X;Y) &= \sum\_{y \in Y} \sum\_{x \in X}  p(x,y) \log{ \left(\frac{p(x,y)}{p(x)\,p(y)}
                              \right) }
\end{align}
$$
# 3. 连锁规则
$$
H(X,Y) = H(X) + H(Y|X)
$$


# 4. 相对熵
　　KL距离，又表示两个概率密度函数p(x),q(x)之间的差异。
$$
\begin{align}
D(p||q) &= \sum\_{x \in X} p(x) log\_{2} \frac{p(x)}{q(x)} \\\\
D(p||q) &= E\_p(log\_{2} \frac{p(x)}{q(x)})
\end{align}
$$



# 参考文献
[1] 维基百科：https://zh.wikipedia.org/wiki/%E7%86%B5\_(%E4%BF%A1%E6%81%AF%E8%AE%BA)




